What do i need to succeed in this course ?

+ Consistency 
+ Practise ( Interviews (Theory))
+ Laptop + External Monitor  ( MAC or windows )    no chromebooks 
+ Earpods 



Divided into two parts
+ Introductory class ( Understand software development lifecyle) and the role you will play 
+ What are the tools we need to succeed as DevOps and Cloud engineers 
+ Linux 
+ Bash shell scripting 
+ Git & Github 
+ AWS 
+ Terraform 
+ Ansible

-------------
+ Jenkins 
+ Docker
+ Kubernetes
+ Maven 
+ Sonarqqube 
+ Nexus 
+ Helm 


help desk channel (engineers working , Senior engineers )

################################################

Slack : Daily communication (announcements )
whatsapp channel : : Announcements (if theres no class , zoom links )
Vimeo : Hands on video 
Confluence: Documentations 
Git & Github : Documenations class running notes 


################################################

5 months (1 month bootcamp ) :
7 months (1 month bootcamp ) : 

zero to hero 
beginner level to master level 


beginner 






FinOps ( Cost optomization )  : cost explorer 
DevOps / Cloud 

Cloud engineer 
platform engineer
cloud security engineer 

slack : remote or hybrid  ; 5 days (work home )  ----> 2 days 



wednessday : 7pm and 10 pm 




What is DevOps 
What is Cloud computing 


mute self 
put on your cameras 

120,000 thousand annually 

100,000 annually ( accept )

110,000 

Lay off 4 people : development -----> High demand ( developers )



[ Collaboration ]

+ Slack : Messaging 
+ Confluence : Class notes Documentation 
+ Jira   : Ticketing 
+ Github   : Class notes (running notes)
+ Whatsapp : Announcements 
+ Telegram :  Videos 



################################

Application software 

Web application :    Software 
Mobile Applications :  software 


system software 

OS - MacOs      ;     software 
Operating system : Windows  : software :


####################
DevOps engineers , Cloud engineers : we are in the business of software development 



**What is Software Developement life cycle :**  

The Software Development Life Cycle (SDLC) is a systematic process software engineers and developers use to design, develop, and test high-quality software. The SDLC aims to produce software that meets or exceeds customer expectations, reaches completion within times and cost estimates, and is efficient and maintainable. The life cycle defines a methodology for improving the quality of software and the overall development process

**Different stages in the software development lifecyle** 


+ Planning : 

This is the initial stage in the SDLC, where the project's scope is determined, and a high-level plan for the project is established. This phase involves determining the resources, team roles, and project goals, and identifying potential risks. The planning stage sets the stage for the rest of the project. This is a critical stage because it can either make or break the process. 

+ Analysis : 

After planning, the next step is to define and document the product requirements and get them approved by the customer or the market analysts. This is done through detailed communication with the project stakeholders.


+ Design 

The requirement specifications from the first phase are studied in this phase, and the system design is prepared. This system design helps in specifying hardware and system requirements and defining the overall system architecture.

+ Implementation (coding)

The software design is translated into source code. All the components of the software are implemented in this phase. This is typically the longest phase of the SDLC.

+ Test : 

: After coding, the product is tested against the requirements to make sure that the product is solving the needs gathered during the requirements phase. During this phase, defects are reported, tracked, fixed, and retested until the product reaches the quality standards defined in the SRS.


+ Deployment : 

After successful testing, the system is deployed to the customer for their use. Sometimes the software is released in stages as per the business strategy of that system.

+ Maintenance : 

Once the system is deployed, and customers start using the developed system, the problems come up and need to be solved from time to time. This process where the care is taken for the developed product is known as maintenance.




Methodology : Simply process or steps taken in deliverying high quality software (app or system software)

**Waterfall Methodology** : (Project Management approach used in software ): Traditional approach 

+ Requirement Analysis 
+ System designs 
+ Implementation ( writing code ) 1 year 
+ testing   : 1 week and fix any issues 
+ deployment : send it out for people see 
+ Maintenance 



**Disadvantages of the Waterfall Model:**

+ Inflexibility to Change: Once a phase is completed, it's difficult to go back and change something. If the requirements were misunderstood from the start, it could lead to a useless product or expensive rework.

+ Late Testing: Testing occurs late in the process, which means any issues found are more expensive and time-consuming to fix. This is because they may require going back several stages to correct.

+ Poor Adaptability: If the client's needs change during development, the Waterfall model struggles to accommodate these changes without significant rework or starting over.

+ Assumption of Perfect Understanding: The Waterfall model assumes that every requirement can be identified before any design or coding occurs. This is often unrealistic, as clients may not know exactly what they need at the outset or may change their minds as they see the project evolve.

+ Delayed Delivery: The product is only tested and delivered at the end of the development cycle. This means clients have to wait longer to see any working software, and it might be outdated or irrelevant by the time it's delivered.



**Agile Methodology**  

Agile methodologies are based on iterative development, where requirements and solutions evolve through collaboration between self-organizing cross-functional teams. It promotes adaptive planning, evolutionary development, early delivery, and continuous improvement, and it encourages rapid and flexible responses to change.

Scrum framework 

+ we can adapt to changes fast 
+ Cost effective 
+ Flexibility and Adaptability: Scrum can easily accommodate changes in requirements and scope.
+ Customer Satisfaction: Regular reviews and iterations ensure that the product meets the customer's needs and expectations.
+ Improved Product Quality: Regular testing and reviews mean that quality is built into the product from the beginning.
+ Increased Project Control: Daily meetings and regular reviews provide better visibility and control over the project.


Interview Question : 

I See on your resume you have stated you have a good understanding of the software development life cycle , as a DevOps engineer can you tell me the role you play ? 



Business Model 

Advertisement : flyers 28th of sept 
Demo session : Invite  
Started the class : First class is free 
going only those that have registered will continue 
Make sure student successful 


SOFTWARE DEVELOPMENT LIFE CYCLE STAGES 

+ Planning 
+ Analysis 
+ Design 
+ Implementation 
+ Test 
+ Deploy 
+ Maintenance 

Development Team -----> Agile methodology (scrum framework)-----> software 

+ Developers
+ Project Managers / Scrum masters
+ 



+ What is a software ?
+ Different types of softwares ( application and system software)
+ SDLC (Software development lifecyle)
+ Methodologies for SDLC (Project) [ Waterfall and Agile( scrum framework )]
+ Development Team 

**Development team is made up of :** 

+ Scrum Masters / Project Managers / Product Owner
+ Developers 
+ UI/UX designers 
+ DevOps Engineers 
+ Cloud Engineers 
+ Q.A testers team ( Quality assurance ) / Test engineers 
+ Database admin 
+ System Administrators 


analogy 

construction  team 

+ builders : tools 
+ Carpenters : Hammer , nails , 
+ Electricians : Cables , Screw drivers , 
+ Plumbers : pipes , 
+ Inspectors : building rules , building permit ,tapes 
+ Building engineers : tapes 
+ Safety engineers : safety helmets , safety boots 



SDLC 

+ Planning (Project managers , scrum masters , products owners )
+ Analysis : (Project managers , Scrum masters , product owners )
+ Design : ( UI/UX designers  + Product owners or project , scrum master ) 
+ Implementation (coding) : Developers (Full stack developer , Backend developers , Frontend Developers )
+ Test : (Q.A or testers or test engineers + DevOps engineers )
+ Deploy ( DevOps )
+ Maintenance ( DevOps + Cloud Engineer + Q.A , Developers )


Software : application software , computer software :  
Infrastructure : on a computer 




#################
# Linux 
###################

Its a simply an Operating system 

+ MacOS 
+ Windows 
+ ChromeOs 
+ Linux ( Computer) 


what is Linux 
why is it important 
why do companies love linux operating system instead of macos or windows 
why 

Different Types of computers 



+ Confluence 
+ Vimeo 
+ Slack class 7 channel 


Python : Automatiom
Bash shell script : Automation 



#################
# Oct 4
#################

All softwares or applications are running on a server (Computer )

What are the different types of computers 

1.  **Personal Computer (PCs)** ( Desktops , Laptops , Tablets )
+ Desktops : General-purpose computers designed for regular use at a single location.
+ Laptops : Portable computers that integrate all components into a single unit, designed for mobile use
+ Tablets : Touchscreen devices that are more portable than laptops, often used for media consumption and light computing tasks

2. **Workstations**: 

High-performance computers designed for technical or scientific applications, often used for tasks like graphic design, video editing, and 3D modeling.

3. **Servers** : 

Computers designed to manage network resources and provide services to other computers over a network (internet). They can host websites, applications, databases, and more.

4. **Mainframes**:  

Large and powerful computers primarily used by large organizations for bulk data processing, critical applications, and large-scale transaction processing.

5. **Supercomputers** 

Extremely fast computers used for complex computations, simulations, and large-scale data analysis, often in research institutions and large organizations.



**A computer has the following components**  

**Hardware Components** Hardware refers to the physical components of a computer system or any electronic device associated to it .This are the things you can touch and see .Hardwares are very important for a computer to function 


**Types of Computer Hardware Components of a Computer** 

+ **CPU ( Central Processing Unit )* 
 
This is like the brain of your computer .Its performs instructions and calculations , Process information (data) and control operations of other things in the computers .

+ **RAM (Random Access Memory)* : 

Temporary storage used by the CPU to hold data and instructions for quick access while the computer is running.

+ **Storage Devices*: 

Storage devices will store information or data permanently or temporarily : These storage devices include 

Hard Disk Drive (HDD) : This is the traditional magnetic storage for data 
Solid State Drive (SSD) : This is a faster storage using a flash memory 
Optical Drives : Devices that read and write data from optical discs (e.g CD ,DVD)

+ **Graphical Proccessing Unit* :

Handles rendering of images and video, essential for gaming, graphic design, and video editing.

+ **Input Devices* : These are devices that allows users to input (put) data (information) into the computer 


Keyboard 
Mouse : Pointing and clicking
Touch Screen 

+ **Output Devices* : These are devices display or produce results from the computers processes 

Monitor : Display visual output 
Webcam : display videos from the computer 
Printer : Produces physical copies of documents or images from the computer 
Speakers : Output sounds from the computer 


+ *Motherboard* : The main circuit board that houses the CPU, RAM, and other essential components, connecting them for communication.

+ *Power Supply Units* : 
Converts electrical power from an outlet into usable power for the computer's components.

+ *Cooling systems* 

Maintains optimal operating temperatures using fans, heat sinks, or liquid cooling systems to reduce heat.

+ *Network Interface Card* : 

Connects the computer to a network, enabling internet connectivity and network communicatio


**Is an external hard-drive an input or output device ?**

An external hard drive is considered as primary storage device .Its not classified as strictly an output or input device but rather its a device used for both input and output functions when we talk about Data Transfer . 



**Software Components** 

1. Operating System (OS)

+ The Operating system is the primary software that manages hardware resources and provides an interface for users to use the computers and also for applications 

2. Applications 

+ Software programs designed for specific tasks
+ Productivity softwares (word processors , spreadsheets )
+ Graphic software : image editing and tooling ( Adobe  Photoshop)
+ Web browswers : Its a software for accessing the internet e.g Chrome , Mozilla Firefox , Safari 
+ Media Players 

3. Device Drivers :

They Specialized software that allows the operating system to communicate or interact  with hardware components (e.g., printer drivers, GPU drivers).

4. Utilities

System software designed to help manage, maintain, and control computer resources (e.g., antivirus software, disk cleanup tools, backup software).

5. Programming Languages and Development Tools:

Software tools used for writing and compiling code (e.g., Python, Java, Visual Studio, Eclipse).



+ Different Types of Computers 
+ Different Components of a Computer ( Hardware and Software )

**Different Types of Operating Systems** 

1. **Windows Operating System** : 

+ **Vendors* : Microsoft 
+ It is widely used on personal computers (Laptops) and servers 

2. **MacOS ( Mac Operating System)**

+ *Vendor* : Apple 
+ Its the operating for apple Mac computers. 

3. **Linux Operating** 
+ Vendors : Various distributions e.g Ubuntu , CentOs , Fendora ,Amazon Linux , Debian , Redhert 
+ Its an open source operating system popularly used by servers , workstations and embeded systems. 

4. **Unix** 
+ Vendors : Various ( IBM AIX ,HP-UX , Solaris)
+ Its a Multitasking operating system often used in servers , workstations . 

5. **Android**
+ Vendors : Google 
+ Its an Operating system for Mobile devices , tablets , Watches 

6. **iOS**
+ Vendors : Apple 
+ This is an operating system for Iphones , Ipads , Apple watches etc 

7. **Chrome OS**
+ Vendor : Google 
+ Its a lighweight operating system used by chromebooks , designed for web based applications 

8. **Solaris**
Vendors : Oracle 
+ Unix-based operating system used by servers and workstations . 



Computer Vendors / Marks

+ Samsung 
+ Dell 
+ Lenovo 
+ HP 
+ Acer 
+ Mac
+ Toshiba 


# LINUX OPERATING SYSTEM 


Linux is a family of open-source Unix-like operating systems based on the Linux Kernel, which was first released in the year 1991 by Linus Torvalds . Its widely used across different computers , servers , mobile devices , 

+ **Open-source** : This means Linux is free to use , modify and you can distribute without needing any license . The source code is publicly available , allowing developers to customize it to fit their needs . 

+ **Multi User Capability** : Multiple users can access the system simultaneously, each with their own settings and permissions, making it ideal or good for environments where many users need to work together.

+ **MultiTasking** : Linux can run multiple processes simultaneously, allowing users to perform several tasks at once.

+ **Linux has Stability and Reliability:** : Linux can run for extended periods without crashing or requiring a reboot, making it a preferred choice for servers.

+ **Linux servers are very secured** : Linux has very strong security features, including user permissions, access controls, and various security modules, reducing vulnerabilities.

+ **Its very portable** 
Linux can run on various hardware architectures, from personal computers to supercomputers.

+ **Its very flexible and customizable** :

Users can customize their Linux distributions (distros) to fit specific needs, including the desktop environment, system components, and applications.


Linux Source Code url : https://github.com/torvalds/linux

**Linux Distributions/Flavour**  

+ Ubuntu 
+ Fedora 
+ Debian 
+ CentOS/RHEL (Red Hat Enterprize Linux)
+ Arch Linux 
+ Linux Mint 
+ OpenSuSe 
+ Amazon Linux 

############################
October 5
############################

Computer vendors : These are companies that sales computers and some of these companies owns the operating system (OS) .It can also be Third party vendors : Best Buy , Amazon , The source , Staples (third party vendors sales computers but they dont produces )

+ Samsung 
+ Dell 
+ Lenovo 
+ HP 
+ Acer 
+ Mac
+ Toshiba 

we will get our Linux servers from AWS : Amazon Web Services : This is a company that provides I.T solutions over the internet called Cloud Computing . You can use the services on a pay as you go basis . 


***HOW TO CREATE AN ACCOUNT WITH AWS** 

+ You need to open the web browser: (https://aws.amazon.com)
+ You need a credit card or debit card 



There Two Ways/Method we can Operate OR Control our Computers 

+ Graphical User Interface (GUI)
+ Command Line Interface (CLI)


With the Linux Operating system we will manage our computers using the Command Line Interface (CLI)

**Why is the CLI more advantangeous than the GUI (Graphical User Interface)**

1. **Its easy for Automation :**

With CLI, you can script tasks, allowing for repetitive actions to be automated, saving time and reducing human error. This is difficult or impossible to achieve with GUI.

2. **It has Speed and Efficiency** 

CLI allows you to execute commands quickly without the need to navigate through multiple windows or menus. This can be much faster once you’re familiar with the commands.

3. **It helps to reduce Resource Usage** 

CLI is lightweight, consuming fewer system resources compared to GUI, which often requires more CPU and memory to display graphics and manage window elements

4. **Its good for managing remote systems** :

CLI is ideal or good for managing remote systems (e.g., through SSH). It's much easier to manage servers and cloud resources remotely with a CLI because it’s not dependent on the graphical environment.

5. **Its customizatble** : 

CLI allows more flexibility to customize scripts, aliases, or batch commands to suit your workflow, while GUI typically has limited customization options.




**HOW TO ACCESS LINUX SERVER IN AWS**

Mac users :  click on launch pad , search for terminal and click on it 
Windows users : click start or menu ----> search for Command prompt or Powershell 

**Step-1**

Open an `ssh client` ----> 
for mac ---> terminal 
for windows ---> command prompt or Powershell 

`Third party ssh clients you can install` 

Visual Studio Code 
Mobaxterm 
PuTTY 
Terminus 

**Step-2**

Locate the private key you created when you launched your EC2-instance 
on your terminal or command you will need to locate this e.g `cd downloads`
because when you create the key it was saved in your download folder on your computer  

**Step-3**

If this is your first time of logging in using this key then you will need to run the following command 

`chmod 400 "yourkey-name1`  e.g `chmod 400 "class7key.pem`

Congratulations you have successful login  ! 


+ As a cloud or devops engineer you can now login into the server (linux)

**Under Linux we will cover the following**

+ Package management 
+ File and Directory Management 
+ User Management 
+ Linux File Permission 
+ Linux File and Directory structure 
+ Linux File or directory Transfer 
+ Process Management 
+ Networking 


**FILE & DIRECTORY MANAGEMENT** 

Note: Linux is Case senstive , make sure you write the commands in `lower case` 

+ What is a `directory` ? In linux its called a directory but using different operating systems we call them `folders`

+ What is a `file` ? : A file is any document that you can create on the linux server : In different operating systems or computers we can refer to them as `documents` e.g can be text document , pdf etc 



**common commands**
`clear` : This clears your terminal 




**DIRECTORY (FOLDER) COMMANDS**

`mkdir <directory-name>` (make directory) e.g mkdir class7 : This will create a directory (foler)
`ls` (list) : This will show you all your directories and files in the current working directory 
`ls -l`(long list) : It will show you your files or directories but with more information e.g permissions , owner and group of the file or directory  ,when the directory was created , size etc  
`ls -a` : List all files and directories including hidden files & directories 
`dir`<directory-name> : List or show you what is inside the folder or directory that is  the content of a directory e.g `dir class7` 
`cd` <directory-name>: cd means (change directory) : This will change from the current directory into a new directory e.g `cd class7` 
`cd ..` : This will move you one directory backward 
`cd ~` : This means you move to the home directory 
`cd /path-to-the directory : Absolute path 
`rmdir` <directory-name> (remove directory) :This will delete the directory only if its empty e.g `rmdir class7`
`rm -rf` <directory-name>: This will force remove the directory because it has content inside
`mv` <old-directory> <new-directory-name> : This will change the name of the directory to a new name 
`mv` <directory>  <path-to-directory> : This is where you want to move the directory to : This will move the directory from one location to another 
`pwd`: (Present working directory) 
`zip -r  <new-zipfile.zip> <name-of-file-you-want-to-zip>` : This will zip or compressed a directory  
`stat <filename> : This display detailed information about the file 
`tree` : This command needs to be installed and to install run ` sudo apt install tree` : The command will show you your directory and file structure in a tree format 
`find` This will search for directories and files matching given pattern . 



**FILE  COMMANDS** 

+ Files can be refered in normal language as our documents . 
what is a file extension : These are file or document types e.g .txt , .pdf  .jpg etc 


`touch <filename>` : This will create an empty file (document)
`vi or vim  <filename>` , next press `i` to insert information .once you are done writing the information , press `ESC` , then press `shift` and continue holding the shift button and then press `:` when u see collon on your terminal type `wq` and press enter 
`nano <filename>` : You can create a file with content 
(vi or vim or nano) text editors will help you to create files with content (information)
`cat <flename>`: This will view the content of a file  
`more <filename>` : This will view the content of a file  
`mv` : can also rename a file and it can also move a file from one directory to another 
`rm` <filename> this will remove files or delete files from your system 
`echo "content of what you want" > <filename>` : This will help you to put information or content into an existing or a new file or it will replace content in an existing file that has content already 
`echo "conetnt of what u want to add >> <filename>` : This will add content to an already existing file with content . it adds and not replace 
`less <filename>` this will allow backward navigation of a file 
`head <filename> or head -n 5 <filename>`  : This will display the last 5 lines of a file 
`tail <filename> or tail -n 4 <filename>` : This will display last 4 lines of the file 
`tail -f <filename>` : This will follow the file for real time updates 
`grep <search-word> <filename>` : This will search for specific strings or patterns in a file and this good for trouble shooting e,g looking for errors in a logs file etc 
`wc <filename>` : This will count lines , words and characters in a file 
`wc -l <filename> : count only lines
`wc -w <filename> : Count only words 
`wc -c <filename> : Count only characters 
`diff <file1> <file2>` comparing files line by line 
`zip  <new-zipfile.zip> <name-of-file-you-want-to-zip> : This will zip or compressed a file 


# USER MANAGEMENT IN LINUX 


User management in Linux refers to the various tasks and processes involved in managing user accounts and their access to a Linux system. It's an important part of system administration, ensuring that only authorized users have access to the system's resources and that they can perform only those tasks for which they have permission. Key aspects of user management in Linux include:


1. User Accounts Creation and Deletion:

+ Creating user accounts to allow new users to access the system.
+ Deleting user accounts when they are no longer needed.

2. Setting and Managing Passwords:

+ Assigning and maintaining secure passwords.
+ Enforcing password policies, like complexity and expiration.

2. User Attributes Modification:

+ Modifying user properties such as usernames, home directories, and default shells.

3. Group Management:

+ Creating and managing groups to simplify permission management.
+ Adding and removing users from groups to control access to files and directories.

4. Managing User Permissions and Ownership:
+ Using commands like chmod, chown, and chgrp to set file and directory permissions and ownership.

5. User Environment Setup:
+ Configuring the environment for users via files like .bashrc, .profile, and others to set up aliases, environment variables, etc.

6. Monitoring User Activity:
+ Keeping track of user logins, logouts, and system usage, often for security and auditing purposes.

7. Implementing Security Policies:
+ Enforcing security policies to protect the system and its data from unauthorized access or misuse.

8. Disk Quotas:

+ Setting disk quotas to limit the amount of disk space and number of files a user or group can use.

9. Sudo Privileges:

+ Managing sudo rights to give certain users the ability to perform tasks as another user, typically the root user, for administrative tasks.



**USER MANAMENT COMMANDS** 

sudo : means `superuser do` It is a command that allows a user to execute or run another command with the security privileges of a superuser (root) or another user. 

sudo is simply a group on the linux operating system where users when added to this group have escalated previllages or administrative permissions just like the root user .

The linux operating systems understands that there certains task that normal users can not carryout. e.g adduser , restarting the system , changing passwords , changing permissions on files .

note ; When you create a new ec2 or linux server it comes with a system user by default e.g 

+ `Ubuntu user` (for ubuntu distributions  )
+ ec2-user (redhert distributions)
+ Both distributions will come with a `root user ` this root users are super admins 


`sudo adduser <user-name>` : This will add user on your linux operating system 
`cat /etc/passwd`: This will output the file and show you the name of the user you just added . 
`cd  /home `: The home directory has the names of all users. you can cd into the home and run the ls command to see all the users e.g `cd /home once ur in run the ls` 
`sudo su - <username` : This will switch to another user on the linux server .  


**USER LOGIN** 

1. `Password Authentication` : Users can login into the linux operating system using password authentication . the following steps below will explain how to configure password authentication 

run the command :  `vi /etc/ssh/sshd_config`
screw down and look for the line that says `#PasswordAuthentication Yes` uncomment the password authentication and make it to look liks this  e.g `PasswordAuthentication Yes` 


2. `Key Pairs` : Users can login into the linux operating using authentication through Key pairs ( private and public key )

Step.1 

+ Create a user on the ubuntu server in aws e.g `sudo adduser <username>`
+ Switch to the new user you created e.g `sudo su - <username>`
+ create a .ssh directory by running the command `mkdir .ssh` this will create a hidden directory 
+ Change directory (move into the .ssh directory you created ) e.g `cd .ssh`
+ Create a file called authorized_keys e.g `touch authorized_keys` make sure to follow the same spellings and and everything has to be lower case .
+ change the permission of the file by running the command `chmod 600 authorized_keys`


Step 2

+ On your local computer , open another terminal and generate an ssh key by running the command 
`ssh-keygen` you will see a prompt like this 

`Generating public/private ed25519 key pair.`
`Enter file in which to save the key (/home/jeff/.ssh/id_ed25519):` 

just keep pressing enter on your keyboard until there are no prompts .

+ cd into the .ssh on local computer and run the command `ls`
+  look for the key file type with the file extension ending with .pub e.g the file will be like this `id_rsa.pub` or  `id_ed25519.pub` 
+ read the file by running the command `cat id_rsa.pub` and then copy the key with your mouse or to copy using a command you can run this ` 
`pbcopy < ~/.ssh/id_rsa.pub`

Step3 

+ Go back into the ec2 or linux server in aws and paste the public key you copied from your local computer or from the user that wants access and paste into the authorized_key file that you created in STEP 1. to open the authorized_key you can run the command `vi authorized_key` or `nano authorized_key` and paste it there 

step 4

go on your local computer and now try to login with the username of the user you created in step 1 or the user you want to give them access to the server by running the following command 

ssh <username>@<hostname or public ip>   e.g `ssh calson@3.98.128.89` and press enter  

the public ip or hostname can be found on your ec2 instance when you click on connect 




ssh-keygen ----> creates two keys ( 1 private key and 1 public key )
                you will copy the public key and give who ever needs to setup the access for you to login

#############
oct 12
############

**user management commands**

+ `sudo adduser`: This will add user on our system 
+ `sudo userdel` <user-name> : This will delete the user account e.g `sudo userdel tom`
+ `sudo usermod -aG <groupname> <username>` :This will modify user account that is adding the user to a group e.g `sudo usermod -aG sudo mary`
+ sudo <groupname> <username >
+ `sudo visudo` go at the end of the file and add the following  `<username>  ALL=(ALL) NOPASSWD: ALL ` e.g `jeff ALL=(ALL) NOPASSWD: ALL` .Jeff will no longer require a password when running the sudo command 
+ `sudo passwd <username>` ;This will change the password of the user 
+ `id <username>` : This will display the user information of all the groups the user is under . You can also write `id` without specifying the name of any user , this simply means you are checking information about the current user . 
+ `sudo passwd -l <user-name>` : This will lock the users account temporary
+ `sudo passwd - u <user-name>` : This will unlock a lock user account 



**group management commands** 
`sudo groupadd <groupname>` : This will create a new group e,g `sudo groupadd DevOps`
`sudo /etc/group`  : This will list all groups in the group file 
`sudo adduser <username> <groupname>` or `sudo usermod -aG <groupname> <username>` : This will adduser to an existing group 
`sudo delgroup <groupname>` : This will delete a group  
`sudo group <username>`: This list or tells you all the groups the user is in . 
`sudo deluser <username> <groupname>` : This will remove a user from the group e.g `sudo deluser mary devops` 
`sudo groupmod -n <new-name> <old-name>:` : This will modify the group name e.g `sudo groupmod -n DevOps devops`
`getent group`: This will list all the groups on the system just like cat /etc/group 
`getent group <name of the group>`: This will list all the users under a specific group e.g `getent group DevOps`



# System Inquiry for users activies command

+ `who` : Shows a list of all users currently logged into the system.
+ `w` : Displays detailed information about users currently logged in, including their activity.
+ `last`  : Displays a list of the last logged-in users.



NEXT CLASS 

# How to login using password authentication 
# FILE PERMISSIONS 




speaks french and english   : 

in canada where cities is the top tech cities 


AWS 


indians 
cameroonians 

english 50 people fighting    5 



team new 
welcome  old 


DEVELOPMENT TEAM 

QA     -------> 20  
DEVOPS -------> 3 
CLOUD ENGINEERS -----> 5 
DEVELOPERS --------------> 60 
SYSTEM ADMINISTRATORS ------>  10 

Permission Management (Groups to simplify user management especially when it comes to permissions )


**LINUX & DIRECTORY FILE PERMISSIONS**  

In Linux as we earlier discussed , linux is very secured . File and Directory Permissions determine who can read , write or execute a file .These are security controls that helps to protect files or directory access . 

`ls -l` : This will show us more information about our files and directories e.g permissions and more info 

**Types of Permissions** 

1. `Read(r)` : It Allows reading the contents of a file(doc) or listing the contents of a directory (folder).
2. `Write (w)` : It  Allows modifying the contents of a file or adding/removing files in a directory.
3. `Execute (x)` : Allows executing a file as a program or entering a directory.e.g running as bash shell script
4. `No permission (-)` This will refuse access to the file or directory  

**Who can these permissions be assigned or given to ?** 

1. `Users (u)`: These are the owners of the file or directory (the person that created the file or directory)
2. `Groups (g)` : These are members of the file group e.g developers , devops 
3. `others (o)` : These are people who are not in the user or the group category 



-rw           -rw           -r--   1   ubuntu  ubuntu       43     Oct 16   21:08    text.txt
read,write    read,write     read       user    group       size   date      time     file name and file ext 

d           rwx                     rwx   r-x 2                     ubuntu ubuntu     4096 Oct 16 21:02 class7
dirctory    read ,write ,execute        read no permission execute   user   group      size date  time directory


**How To Change Permissions for Files and Directories**

There are two ways we can change permissions to files and directories 
The command to change permissions is 

`chmod` : This command will help you to change permission 

`chmod     400          "handson.pem"
command    permission     file 

1. **Numeric (Octal) Mode** These uses numbers to assigned permissions 

Read = 4
Write = 2
Execute = 1
No permission = 0 


-rw-rw-r-- 1 ubuntu ubuntu       43 Oct 16 21:08 text.txt
 
`chmod 766 <filename>`

Read - No permission  - no permission 


**Symbolic Mode** 



file :  backup.txt 
users : rwx 
group : rw
others : r


chmod 764 backup.txt 


file: password.txt 
users : r 
group : r 
others : - 

chmod 440 password.txt 


directory : welcomehome
users: rwx
group : rwx 
others : rwx

chmod 777 welcomehome 

file : recover.txt 

user : r 
group: - 
others - 

chmod 400 recover.txt 




2. Symbolic Mode : 

This is a method of changing file or directory permissions using `characters`  instead of numberic codes (numbers) 

1. User Categories 

Users (u)
Groups (g)
Others (o)
All users (a) : users , group and others 

With Symbolic Mode we have what is called Operators 

**how will the command be structured ? see below**

Who ?   the category we want to give permission e.g user (u) ,group (g) others (o) or all (a)
Operator :  + - =
Permission  : Read (r) , Write (w) , Execute (x), No permission (-)


**Operators** : This helps to define how permissions are modified 

+ : This adds a permission 
- : Removes permission 
= : This sets permission and overrides (takes over) the existing ones 

chmod u+r <filename>

-rw-rw-r-- 1 ubuntu ubuntu  113 Oct 10 01:33 doc2

-rwx rwx-r-- 1 ubuntu ubuntu  113 Oct 10 01:33 doc2

chmod ug+x doc2

chmod g-wx doc2

chmod a+wx doc2

**Note** : Directories have seperate permissions regardless of what the files have as permissions 

d rwx rwx r-x 2 ubuntu ubuntu 4096 Oct 24 00:00 Canada

d - directory 
user : rwx 
group : rwx 
others : r-x

rx

**Changing Ownership of Files & Directories** 

we will use `chown` command to change ownership of files and directories from one user to another 

Example `chown <new-username> <filename>  (`chmod grace canada`)


To change change group we will need to run the following command `chgrp` . This will change the group that owns the file or directory 

example `chgrp <new-group-name> <file or directory> e.g `sudo chgrp deVops Canada`

**Additional Tips:**

+ To apply changes recursively to all files and directories within a given directory, use the -R option. For example, `chmod -R 755 <directory_name>` will apply the permission changes to all files and directories inside directory_name.

e.g : `chmod -R 400 Canada` 

+ Only the owner of a file or a superuser (root) can change the ownership of a file.
+ You need appropriate permissions to change the group of a file. Generally, you should be the owner of the file or a superuser.
+ It's important to be cautious when changing permissions and ownership, especially as a superuser, as incorrect settings can affect system security and functionality.


**LINUX FILE OR DIRECTORY TRANSFER** 

File sharing ? 

This will show you the different methods or approach you can use to move or transfer files or directories from one user or location to another within the same linux server or another server. 



1. `cp` : This command will copy files & directories locally (same linux machine)
to copy a file e.g `cp <filename> <destination (where u want to send the file)> 
to copty a directory e.g  `cp -r <directortname>  <destination (where u want to copy the directory)>

2. `mv` : This command will move files from one location  to another locally (same linux machine)
to move a file e.g `mv <file or directory name> <destination (where u want to move the file to)>

3. `scp (secure copy protocol )`

Securely transfer files between two machines over a network using `SSH`. This can be transferred through two remote machines or a local and a remote machine

scp source_file_path username@destination_host:destination_folder 

SCP can move files from one user to another within the same linux system or from one linux system to another using ssh . 

**To transfer files from one system to another use the follow command** 

`scp source_file_path username@destination_host:destination_folder`
e.g  `scp <filename> <username@hostname:<destination>
      `scp text.txt grace@15.157.71.16:/home`   this will prompt for you to put the users password 


**To transfer files from same linux server that is one user to another within the same system**
e.g  `scp <filename> <username@hostname:<destination>
      `scp text.txt grace@localhost:/home`  this will prompt for you to put the users password 


4. `rsync** :` 

Synchronize files and directories between two locations with minimal data transfer, using compression and incremental copy.The rsync command is used for transferring files and directories between local and remote systems. It is efficient and can resume interrupted transfers

rsync options source destination

`rsync -avz -e ssh /local/dir user@remote.server.com:/remote/dir`
`rsync -avz <filename> <username@hostname:<destination>
e.g `rsync -avz welcome.sh grace@15.157.71.16:/home` this will prompt for you to put the users password 

to use rsync to copy within the same linux system 
`rsync -avz <username>@localhost:/home` this will prompt for you to put the users password 


**different flags for rsync** 

`Sync a local directory`: rsync -avh source_directory/ destination_directory/
`Sync a local directory to a remote server:` : rsync -avh source_directory/ user@remote_host:/path/to/destination/
`Sync a remote directory to the local system:`: rsync -avh user@remote_host:/path/to/source_directory/ destination_directory/


rsync -e text.txt calson@935.670.596:text.txt 

| **Flag**          | **Meaning**                                                                                 |
|-------------------|---------------------------------------------------------------------------------------------|
| `-a`              | Archive mode; preserves permissions, timestamps, symbolic links, and other file attributes. |
| `-v`              | Verbose; provides detailed output of the transfer process.                                  |
| `-z`              | Compress file data during the transfer, useful for speeding up transfers over slow connections. |
| `-r`              | Recursively copy directories and their contents.                                           |
| `-u`              | Skip files that are newer on the receiver.                                               |
| `-n` or `--dry-run` | Perform a trial run with no changes made; shows what would be copied.                     |
| `-e`              | Specify the remote shell to use, e.g., `ssh` or `rsh`.                                     |
| `--delete`        | Delete files in the destination that are no longer present in the source.                |
| `--progress`      | Show progress during transfer.                                                             |
| `--exclude`       | Exclude files matching a pattern from being copied.                                       |
| `--link-dest`     | Create hard links to files in a specified directory if they have not changed.              |
| `--partial`       | Keep partially transferred files to allow resuming later.                                  |
| `--bwlimit`       | Limit the bandwidth used by the transfer, specified in KB/s (e.g., `--bwlimit=100`).      |
| `-h`              | Human-readable output; shows file sizes in a more readable format (e.g., KB, MB).          |
| `-p`              | Preserve permissions of the files during transfer.                                         |
| `-t`              | Preserve modification times of the files.                                                 |
| `-o`              | Preserve owner of the files (requires root privileges).                                   |
| `-g`              | Preserve group of the files (requires root privileges).                                   |



5. `sftp (SSH File Transfer Protocol)`

Interactive file transfer session that uses SSH to secure the transfer.
Start an SFTP session with a remote server

sftp <user-name>@<hostname>
e.g `sftp calson@35.183.48.28`  
when you run the command it will prompt for a password , input the user password and you should see something like 

`Connected to 35.183.48.28.`
`sftp>`   `e.g put <filename>  press enter `

 Once connected, you can use commands like get, put, ls, cd, etc., to manage and transfer files.


6. `ftp (File Transfer Protocol)`

Transfer files between systems on a network. Less secure than scp or sftp as it does not encrypt data.

e.g `ftp remote.server.com`


**FILE LINUX STRUCTURE** 

The linux operating system is made up of (files and directories )

The Linux file system structure is a hierarchical filesystem structure, much like a tree with branches, used by Linux operating systems. At the root of this structure is the root directory, denoted by a single slash (/), from which all other files and directories branch off. Below are the key directories found at the root level of the Linux filesystem and their purposes:

In Linux we have two types of files and directories . we have directories and files that came with with the system and we call them system directories or files (root directories)

Root directories : These are directories (folders) that came with the operating system
user directories /files : these are directories or files that were created by users 

`/` :  (Root Directory): The top-level directory in the filesystem. All other directories are subdirectories of this one, hence it is referred to as the root.

`/bin`: Contains essential binary files (commands) such as ls, cat, vi, etc. These are fundamental commands needed in single-user mode and for basic system functionality.

`/opt`: Used to store additional software and packages downloaded for the system. It's a common location for software not included with the distribution package.
it comes empty and its the best practise to download any new software or packages in this directory 

`/boot`: Contains files necessary for system boot-up (start), including the Linux kernel, initial RAM disk image, and bootloader configuration files (like GRUB).

`/etc` (`configuration files`): Houses system configuration files and scripts that control the behavior of various aspects of the system.

`/home`: Home directories for users. Each user on the system has a directory here for personal storage, configuration, etc.

`/lib (/lib32, /lib64)`- Libraries: Contains essential shared libraries and kernel (base os) modules needed by the binaries in /bin and /sbin. These are critical for the basic functioning of the system.

`/media`: Designated as a mount point for removable media devices like USB drives, CD-ROMs, etc.
These directory is empty by default 

`/mnt (mount point)`: Typically used as a temporary mount point for mounting filesystems manually.
this directory also comes empty by default

`/sbin`(system binaries):  Contains system administration binaries. These are essential for booting, restoring, maintaining, or recovering the system. Examples include reboot, fdisk, fsck. .These are critical for system maintenance and typically require root privileges.

`/srv`:(service data) Holds data for services provided by the system, like web servers, FTP, and others.
+ this directory is empty by default 

`/tmp:(Temporary Files)` A directory for storing temporary files used by the system and applications. Files here are typically short-lived.These files can be deleted after system reboot or after a set time

`/usr :(user programs and libraries)` This is one of the largest directories and contains additional user applications and utilities. It has several subdirectories. It contains applications and files not critical to booting:

`/usr/bin`: Contains user binaries or executable files.
`/usr/include`: Stores standard include (header) files for C and C++ programming.
`/usr/lib`: Library files for /usr/bin and /usr/sbin.
`/usr/local`: Local hierarchy for software installed manually (not managed by the package manager).
`/usr/share`: Architecture-independent data like documentation, icons, fonts, etc.
`/usr/src`: Source code, usually for the Linux kernel.


`/var (Variable)` variable data means something that will constantly change. Designed for files whose content is expected to grow, these include:

`/var/log`: Log files with system log information. a log is a file with a series of events that are being saved from your operating 
`/var/spool`: Spool direcory contains directories for tasks like mail, printer queues, and cron jobs.
`/var/cache`: Cached data from application programs.
`/var/lib`: Dynamic data libraries and files that describe the current state of installed applications.
`/var/tmp`: Temporary files preserved between reboots.

 
# HARDWARE MANAGEMENT IN LINUX

**Hardware information commands** 

`cat /proc/cpuinfo` : Provides detailed information about the CPU of ur server
`lscpu`:  Displays detailed information about the CPU architecture.
`lsusb` : Lists USB devices connected to the system



**Memory Information**

`free -m` : Shows the total, used, and free memory in the system in megabytes.
`cat /proc/meminfo` : Displays detailed information about the system memory.

**Disk Information**

`lsblk` : Lists block devices, such as disks and partitions, in a tree format.
`df -h` : Displays disk usage of all mounted filesystems (storage).
`fdisk -l`: It shows partition tables for all disks

**PCI Devices** (Peripheral Component Interconnect) 
devices are hardware components that connect to a computer’s motherboard through the PCI or PCI Express (PCIe) slots. PCI and PCIe are standard interfaces that allow peripheral devices to communicate with the CPU, memory, and other system resources, and are commonly used in desktop computers, servers, and workstations.

`lspci`: Lists all PCI devices

**SCSI Devices**

`lsscsi`: Lists SCSI devices (or hosts and their attributes).

**Hard Disk Data**
`hdparm -I /dev/sda`: Retrieves information about the disk like make and model (replace /dev/sda with your disk, requires root privileges).


**Disk Usage**
`du` : Estimates file and directory space usage.

**Hardware Information (General)**
`lshw`: Displays detailed information on the hardware configuration (requires root privileges for detailed info).
`hwinfo`: Shows detailed information about the hardware (may need to be installed separately).

**Temperature Sensors** : 

`sensors`: Displays temperatures, voltages, and fan speeds (requires lm-sensors package).

**Graphics Card Information**

`lspci | grep VGA`: Lists VGA graphics adapters and their details.

**System Architecture**

`uname -m`: Displays the machine hardware name (architecture).


# PROCESS MANAGEMENT

What is Process Management and Its Importance 

Process management in computing refers to the control and coordination of all active processes on a system. Processes are instances of programs in execution (running), and managing them involves tasks such as starting, stopping, monitoring, and optimizing them to ensure that the system functions efficiently. In Linux (and other operating systems), process management helps keep the system stable, ensure optimal performance, and prevent resource conflicts.

**Importance of Process Management in DevOps and Cloud**

1. Resource Optimization ;This helps you to see which processes are consuming alot of your resource e,g CPU and you can stop the process to enhance the perfomance of your server. 

2. Application reliability : Managing processes ensures that critical services are always running and responsive, minimizing downtime for end-users and improving service availability.

3. Trouble shooting and debugging : Understanding and controlling processes is key to diagnosing issues. If an application crashes or experiences performance issues, effective process management allows for quick identification and resolution of problematic processes.

4. security and compliance : Managing processes helps ensure only necessary services are running, reducing attack surfaces and enabling better security monitoring and auditing.


# PROCESS MANAGEMENT COMMANDS

1. **Viewing Processes commands** 

`top` : An interactive command that shows a real-time view of `running processes`, along with system resource usage like CPU and memory.

`htop`: An enhanced version of top with a more user-friendly interface and additional features (may need to be installed separately).

`ps`:  Displays information about active processes. For example, ps aux shows detailed information about all running processes.

`ps aux`: shows all processes in detailed format
`ps -ef` : another common format to list all processes


2. **Controlling Processes**

Each application you have open on your system (computer) or service is called a process and each of them are being identified with what we call a process I.D .
Note ; These process i.d are unique for each process and they are dynamic meaning if a process is stopped and restarted it comes with a new process i.d (PID)

1. `kill` : its Sends a signal to a process, commonly used to terminate it.
e.g `kill <PID>`(process id)   `kill 9384` : Gracefully stops process wurg spefic id 
+ `kill -9 <PID>`     : This will forcefully terminates process 
+ `killall` : Terminates all processes with a given name, e.g., killall [process_name]
+ `pkill` : Allows you to kill processes based on criteria like name, user, group, etc., e.g., pkill -u [username].  e.g pkill -u [username] this will kill all processes running by the user  
+ `xkill` : A graphical tool to terminate a misbehaving X client; when run, you can click on a window to kill its process.

3. **Managing or adjusting Process Priorities**

`nice` : Starts a process with a specified priority (niceness). Lower values mean higher priority.Niceness levels range from -20 (highest priority) to 19 (lowest priority)

e.g `nice -n -10 -p [process.id]`; Starts a process with a specified priority (niceness). Niceness levels range from -20 (highest priority) to 19 (lowest priority).
    
`renice`: Changes the priority of an already running process, e.g., renice -n 10 -p [process_id]. 

4. **Process Suspension and Background Execution**
 `&` : using & allows you to run processes in the background  e.g sleep 60 &

In this example:
sleep 60 pauses the command for 60 seconds.
`&` places the sleep 60 command in the background.

`bg` : Resumes suspended processes in the background.
`fg` : Brings a background process to the foreground.
`jobs` This command see all background jobs (processes)

5. **Monitoring System Activity**

`vmstat` : Reports virtual memory statistics, including process, memory, disk, and CPU information.
`pstree` : Displays running processes as a tree, showing their parent-child relationships.

6. **Managing Daemon Processes / System Services**
These are services or processes that are managed and run by our operating system 

what is a deamon process , this refers to `daeomons`, these are background processes that runs continously to perfomr various tasks and procide system services common examples includes web servers , database servers and system loggers . Daemons usually start during the system boot(when the system is starting ) process and run silently in the background, without direct interaction with users, handling tasks essential for system functionality.

`systemctl start <servname>`  ;  This starts a service 
`systemctl stop <service-name>` : stop service 
`systemctl status <service-name>`: this see if the service is running or stopped 
`systemctl restart <server-name>`: This will restart the service 


7. **Viewing Process Status**

`pidof`: Finds the process ID of a running program, e.g., pidof [program_name].
`pgrep`: Searches for processes based on name and other attributes.


# NETORKING COMMANDS 

`Why is knowing networking commands in Linux Important to you as a Linux Admin , DevOps , Cloud Engineer , Cloud security engineer etc `

Networking commands in Linux are essential for DevOps ,Linux and cloud engineers as they help configure, monitor, and troubleshoot network settings and connectivity. In cloud and DevOps roles, understanding these commands is critical for tasks like configuring network interfaces, setting up security, managing connections between services, and diagnosing network issues that impact service availability and performance.

1. **Testing Network Connectivity commands** 

+ `ping` : Sends ICMP ECHO_REQUEST packets to network hosts to test if they can communicate. if you see request timeout then check to make sure security groups for your instance allows in bound traffic for ICMP 1pv4 . 
`e.g ping [address]`   ping 35.183.48.28 note use the (public ip)

+ `traceroute [address]`: Traces the route taken by packets to reach a network host.
+ `tracepath [address]`: Similar to traceroute but doesn’t require root privileges.

2. **Checking Network Configurations**

`ifconfig`:  Displays the current network configuration for all interfaces. (Note: ifconfig is deprecated vor of ip command in newer Linux distributions.)

`ip addr show`: Shows addresses assigned to all network interfaces.

`ip link show`: Displays the state of all network interfaces.

3. **Modifying Network Configurations**

`ifconfig [interface]`: Configures or displays network interface parameters.

`ip addr add [address] dev [interface]`: Assigns an IP address to a network interface.

`ip link set [interface] up/down` : Activates or deactivates a network interface.

4. **Viewing and Managing Routing Table**

`route` : Shows or modifies the IP routing table
`ip route show` : Displays the routing table.
`ip route add/del [route]`: Adds or deletes a route

5. **Network Connections and Statistics**

`netstat`: Shows network connections, routing tables, interface statistics, masquerade connections, and multicast memberships.

`ss`: An alternative to netstat that displays sockets.

6. **DNS Lookup** (Domain name service)

`nslookup [address]`: Queries(it sends a request) Internet name servers interactively for DNS information
`dig [address]` : Performs DNS lookups and displays the answers.

7. **Network Interface and Protocol Statistics**:

`iwconfig`: Configures wireless network interfaces (replaced by iw in newer systems).
`iwlist [interface] scanning`: Displays a list of available Wi-Fi networks.
`iw`: Shows and manipulates wireless devices and settings.

8. **Monitoring Network Traffic**

`tcpdump`: Dumps traffic on a network (requires root privileges).
`wireshark`: A GUI network protocol analyzer (requires installation).

9. **Network Security and Firewall**  

`iptables`: User-space utility program for configuring IPv4 packet filter rules.
`ufw`: Uncomplicated Firewall, a user-friendly frontend for managing iptables (requires installation).e.g `ufw status` 
`firewall-cmd`: Firewall management tool for systems using firewalld.


10. **Bandwidth Testing and Monitoring**

nmap: Network exploration tool and security / port scanner.
iftop: Displays bandwidth usage on an interface.
iperf: Tests network bandwidth performance.

11. **SSH and SCP for Secure Network Communication**

ssh: Securely connects to a remote machine.
scp: Securely transfers files between hosts over the network.

13. **Network File Sharing**

samba: Provides file and print services to SMB/CIFS clients.
nfs: Manages NFS network file system


Network commands you should master

+ Ping 
+ Traceroute or tracepath 
+ nslookup 
+ hostname 
+ ifconfig 


# PACKAGE MANAGEMENT 

Package management in Linux refers to the methods and tools used to install, update, configure, and remove software packages on a Linux system. A package is a compressed file archive that contains all the files necessary to install a particular software program or library, along with metadata about the package like its version, dependencies, and a description of what it does.

`Different types of Package Managers`

**Package manager for Debian(Ubuntu , debian  etc)**

+ `apt or apt-get ` (Advanced Package Tool) : This package manager is used for Linux distributions like Debian (Ubuntu ,Debian )

`apt install tree` : This command installs tree using package manager apt  

`apt install <package name>`
`apt update` 
`apt remove` 
`apt upgrade` 
`apt uninstall <package name>`


***Red Hat (CentOs , Fedora , Redhat)**

`yum` 

`yum install tree` 
`yum install <package name>`
`yum update` 
`yum remove` 
`yum upgrade` 
`yum uninstall <package name>`

**other package managers** 

`dnf` : u can use this with Fedora, centOs ,Redhat 
`snap` : Univeral Package Manager  
`flatpak` :Universal package manager 

##################

`wget` :  wget is a command-line utility used for downloading files from the web. It's a powerful tool that supports various protocols, including HTTP, HTTPS, and FTP.



`Package Manager for Mac `

`brew` is the package manager for MacOs

**Note** to use brew package manager on your macOS you need to install it using the command 

`/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"`   

you can get the command from this website  `https://brew.sh`



to confirm if brew has been installed run the following command 

`brew --version` you should see an output like this
 `Homebrew 4.3.9`

e.g `brew install tree` : 


##########################
## Windows Package Managers  
##########################


+ `Chocolatey` e.g choco install <packagename>
                 choco update <packagename>
                 choco uninstall <packagename>
note: to use chocolatey package manager on windows you need to install cholatey by following the website to install    https://chocolatey.org/install


+ `Winget` e.g winget install <package_name>
            winget upgrade <package_name>

+ `Scoop` e.g scoop install <packagename>


## Package Type or File Type  ( file extensions)

+ Files installed from the internet will come in a compressed format .
+ Files , softwares or applications in compressed format cant be used until you deflate .

## Zip  (extension .zip) for example welcome.zip 
To use the zip command you need to install zip 

## Tar (tape archived ) (exention .tar) for example file.tar 
## Rar (extenstion .rar) :
For extremely large files , data compression ,error rcovery and file spaning 
## Gzip : compression better .zip 


# Importance or Benefit of Package Management 

+ Security : Regular updates , patches helps protects software or server from attacks
+ It simplifies software installation (package managers helps simplify the process).
+ stability and consistency   : Package managers maintain the versions of your software installed allows users to be able to install a specific version or can roll back to previous versions . 
+ System Management .you can use package managers to maintain system configurations 



**BASH SHELL SCRIPTING** 

+ File and directory management 
+ File and directory permissions 
+ Directory Structure in Linux 
+ User Management 
+ Process Managament 
+ Hardware management 
+ Networking 
+ Package Management 
+ file and directory transfer 

text.txt
    .pdf 
    .jpg 
    .sh 




## Package Type or File Type  ( file extensions)
+ Files installed from the internet will come in a compressed format .
+ Files , softwares or applications in compressed format cant be used until you deflate .

## Zip  (extension .zip) for example welcome.zip 
To use the zip command you need to install zip 

## Tar (tape archived ) (exention .tar) for example file.tar 
## Rar (extenstion .rar) :
For extremely large files , data compression ,error rcovery and file spaning 
## Gzip : compression better .zip 


# Importance or Benefit of Package Management 

+ Security : Regular updates , patches helps protects software or server 
+ It simplifies software installation (package managers helps simplify the process).
+ stability and consistency   : Package managers maintain the versions of your software installed allows users to be able to install a specific version or can roll back to previous versions . 
+ System Management .you can use package managers to maintain system configurations 




**BASH SHELL SCRIPTING** / scripts or programming 


we are going to split the word bash shell scripting , what is bash , what is a shell and what is scripting 

1.  What is `Bash shell` :  Its a command line processor which typicaly runs in text window where the user types commands which causes an action . ( An interpreter)  used for linux and unix-like operating systems .

+ Bash, short for "Bourne Again SHell," is a command-line shell and scripting language for Unix and Linux operating system


2. `Bash Shell Scripting` : is a file contains a series of commands (Linux Command ) written in Bash programming language .This scripts Automate Task on Unix-like operating systems like Linux 


development team 

+ Q.A team 
+ UI/UX designers 
+ Software engineers ( Developers)
+ DevOps 
+ Cloud Engineers 
+ Data scientist 

programming language : developers will write scripts 

bash shell script 
python script 
nodejs script 
java script 

**What is the importance of Bash Shell scripting** 

1. Its helps in `Automating Repetitive task` :  Shell scripts can automate manial and repetitive tasks such backups, system updates , log file analysis  by doing reduces manual intervention and saves time 

2. `It increases Efficiency and Productivity`bash shell scripts help to increase efficiency and productivity fpr example Administrators ,DevOps , cloud engineers write and can schedule scripts to run at specific times or events, allowing them to focus on more different activities.

3. `Scrtipting brings in Consistency` , Task with scripts ensures that the perform the same all the time . it reduces human errors and increases reliability .

4. `Flexible` : it can be used to carryout any kind of task from simple to complex task



**Differences between shell and programming languages**.

python , java , javascript , c , c++ , ruby , golang , php ,Typescript ,Rust , Kotlin , Bash shell script 

- Python 
- Bash shell script 

1. `purpose of a shell script` : Designed primarily for interacting with the `operating system`  and executing commands e.g linux , mac , windows . They facilitate automation of command-line tasks, process management, and file manipulation.

while other programming languages like c++, typescript are called general programming languages they are used to create software applications and carry out complex data structures .They are designed for developing programs that can run independently.

2. `Syntax & Structure` : Typically have a simpler and more concise syntax. Commands are usually line-oriented and can be executed directly in a terminal. while other programming languages or general programming languages 

Often have more complex syntax and structure, including support for concepts like classes, objects, and modules. They require a compiler or interpreter to run the code.

what is a syntax can be called a format 

3. `file extensions are different from other programming langangues` e,g bash shell script the file extension ends with .sh while python script ends with .py 

4. `Bash shell is used automation` 


**What are some of the shells our operating has which we can use to run scripts or commands on our CLI**

1. **Bash** (`Bourne Again Shell`)

- This is the default shell for many Linux Distributions  and MacOs 
- it has Some features like command line editing , job control ,scripting capabilities , shell functions 

2. **sh bourne Shell** 

+ This was the original Unix Shell Developed by Stephen Bourne  .This has less features when compared to Modern shells for example Bourne Again Shell. 
+ Key features : Simple scripting languages , Available widely with Unix -system


3. **csh (C shell)**

+ It was developed by Bill Joy at University Of California 
+ It has advanced features for interactive use and it has features
c-like syntax , history mechanism , job control .

4. **ksh (korn shell)**

+ David Korn developed the korn shell . At&T Bell Labrobartory . 
it has features from both the C-shell and the born shell  
+ It has advanced scripting features ,floating point arithematics , associative arrays

5. *** Zsh (Z shell )***

+ Its a very powerful , you can figure it easily than the other shells and its designed for interactive. Includes features from Bash ,Ksh ,tcsh , and it has its own unique enhancements . 
Features : all features for Bash , Ksh ,Tcsh and spell checking , theme support , plugin frame works

6.  **tcsh (Tenex C shell)** 

+ This is an enhanced version of the c-shell 
+ features like command line editing , spell corrections ,


**Windows**

+ Powershell 
+ cmd 
+ Git bash 



**Best Practise while writing a Bash shell script** 

1. **Start your bash shell scripts with `SHEBANG` e.g  `#!/bin/bash`**

Start your script with a shebang (#!/bin/bash or #!/usr/bin/env bash). This specifies the interpreter that should be used to execute the script.

2. **Use Comments** 

Include comments to explain what the script does, its parameters, and any complex logic. This improves readability and helps others (or your future self) understand the script and maintain the script.

There two ways you can write a comment in a script 
+ Single line comments e.g    `#this is a script to automate back` 
                               #run this script if you have sudo previllages
+ Multi -line comment e.g :<<"comment" 
                        this is a script to automate tak 
                        run this script if you have sudo previllages
                        this script was written by calson 
                       comment 

 3 **Follow good naming conventions**   : Use meaningful variable names and consistent naming conventions (e.g., lowercase with underscores for variables). This makes your code easier to read and understand.Also give save your scripts with good names that could simply explain what the script is all about . 

 4 **Avoid hardcoding** : Instead of hardcoding values directly into the script, define variables at the beginning. This allows you to change the value in one place rather than throughout the script.

database = "158.475.5869"

echo"connecting to database $database
login "echo successful login into database $database
password change "echo password has been successful updated for dbbase $database


 5 **Handle sensitive data accurately**  : Do not hardcode sensitive data like passwords , api keys , tokens instead handle them using environmental variables , Secure Configuration Files , Use Hashing or Encryption like base64 or you can Prompt for Sensitive Data  `read -s` etc  

db = `welcomehome`  #this is wrong do not hardcode sensitive data in your script 

instead use environtal variables :  
e.g `vi ~/.bash_profile 


 6 **Use modules as much as possible**  : It promotes better organization, reusability, and maintainability of your scripts. Modules allow you to enclose or bring together related functions, variables, and logic into separate files, making your scripts cleaner and more manageable

 `exampe of a module` 

 # db_operations.sh
function connect_db() {
    local db_host="$1"
    local db_user="$2"
    local db_pass="$3"
    echo "Connecting to database at $db_host with user $db_user"
    # Add database connection logic here
}

# utils.sh
function log_message() {
    local message="$1"
    echo "$(date +'%Y-%m-%d %H:%M:%S') - $message"
}


 `directory structure example of how you can arrange a module in bash shell ` 

 ├── main_script.sh
 └── modules
    ├── db_operations.sh
    └── utils.sh


 7 **Always test your scripts** : Test your scripts to make sure they function as expected in a controlled environment e.g sandbox , or your own aws account before applying in a production . 

 8 **Implement good error handling** :Use error handling to manage unexpected situations. You can use trap to catch errors or implement custom error messages and exit codes or you can use echo statements to handle troubleshootig scenarios in the script . 

 testing :  Sandbox environment 
            dev environment 
            stage environment 
            production environment 
            logs archive 
            shared -service account 




**Different Syntax in a Bash Shell Script** 

Syntax simply means what is the format or how do we arrange the script or commands or logic inside the file e.g bash shell script 

1. `Shebang` : The shebang (#!) indicates the interpreter to be used. For Bash scripts, it typically looks like this: e.g   ` #!/bin/bash`
 
                                     
2. `Comments` : Comments helps to annotate or describe ,explain the script and its uses the `#` on that line and the interpreter (bash) ignores the line because its a comment and only execute or run other lines of the code that dont have the #  e.g ` # this is a comment `

3. `Variables`: Variables are created by assigning data sets or values that will be used in the script .Variables helps to avoid hardcording of your bash shell script and makes the script dynamic. There are different types of variables 

+ **user define variables* : These are variables users will setup in their bash shell script especially in the beginning of the script
+ **system define variables* : These are variables that comes with the Operating system (Linux) and they are written in Upper_case letters 
+ *environmental variables* : These are variables that are saved in the users local environment its being used by the intepreter (bash , cshell , sh ) e,g you can save these variables in the following path : ~/.bash_profile or ~/.bashrc 

`example of a user-define variable`

e.g variable_name=value     
    name = calson

to call a variable in your script you will use the $  e.g 

#!/bin/bash 

# This script welcomes users to Team4tech solutions company 

#user define variables

company="Team4tech Solutions"
name="Calson" 
class="class7" 
course="Devops and Cloud Computing" 

echo "welcome to $company ! we are happy to have you $name"
echo "This is $class and we are studying $course"


4. `Conditiional Statements` ( if , else , elif )

Conditional statements in Bash are used to execute or run specific blocks of code based on whether a condition evaluates  to true or false. This allows you to create scripts that can make decisions and handle different scenarios. The primary conditional statements in Bash are `if, else, and elif`.

+ `if statement` : 
The if statement evaluates(looks) a condition and executes a block of code if the condition is true.
+ `else statement` : 
The else statement follows an if statement and provides an alternative block of code that executes if the condition in the if statement is false.

+ `elif statement`
The elif (short for "else if") statement allows you to check multiple conditions. You can have multiple elif statements between an if and an else.

`e.g syntax `

if [ "condition" ]; then
    command
else 
    command 
fi 

`below is an actual example 1`

number=7
if [ $number -gt 10 ]; then
    echo "$number is greater than 10."
elif [ $number -gt 5 ]; then
    echo "$number is greater than 5 but less than or equal to 10."
else
    echo "$number is 5 or less."
fi

**Numeric Comparisons:**

-eq: equal to
-ne: not equal to
-gt: greater than
-lt: less than
-ge: greater than or equal to
-le: less than or equal to

e.g 

`example number 2`

#!/bin/bash

echo "welcome to RBC ATM MACHINE"

read -p "Enter your PIN " pin 

if [ "$pin" == "1234" ]; then 
   echo "you have succesfully login!"
else 
   echo "wrong pin try again!" 
fi 



# LOOPS (For loops , While Loops , Unitl Loops ) 

Loops allows you to repeat commands or a block of code  multiple times within your script. 
There are different types of loops e.g For loops , While Loop and we have the until loop 

1. `For Loops` A for loop in Bash allows you to iterate (goes through) over a list of values or files. It's helpful when you want to perform a repeated action on each item in a list.  
10 items 

`Syntax or Format`

for variable in list; do 
# commands 
done 

`example` 

for 1 in 1 2 3 4 5 6; do 
 echo "Number: $1
done 


2. `While Loops`: A while loop in Bash continues to execute a block of commands as long as the specified condition is true. This type of loop is useful when the number of iterations is not known in advance. 

`Syntax of Format for While`

while [condition]; do 
  # commands 
done 

`example` Basic counter 

#!/bin/bash
counter=1
while [ $counter -le 5 ]; do 
 echo "Number: $counter"
 ((counter++))
done 



3. `Until Loop` : An until loop is similar to a while loop but runs until the condition becomes true (opposite of while). It is useful when you want the loop to execute until a certain condition is met.

syntax 

until [condition]; do 
 #commands 
done 

e.g Basic : counter script 

#!/bin/bash

counter=1 
until [$counter -gt 5]; do 
 echo "number: $counter"
 ((counter++))
done 

## Numeric Comparison Operators in Bash

In Bash scripting, numeric comparison operators are used in conditions to compare integer values. Below is a list of common comparison operators with their meanings and examples.

| Operator | Meaning                      | Example                 |
|----------|------------------------------|-------------------------|
| `-eq`    | Equal to                     | `[ "$a" -eq "$b" ]`    |
| `-ne`    | Not equal to                 | `[ "$a" -ne "$b" ]`    |
| `-gt`    | Greater than                 | `[ "$a" -gt "$b" ]`    |
| `-ge`    | Greater than or equal to     | `[ "$a" -ge "$b" ]`    |
| `-lt`    | Less than                    | `[ "$a" -lt "$b" ]`    |
| `-le`    | Less than or equal to        | `[ "$a" -le "$b" ]`    |


# DIFFERENCE BETWEEN WHILE LOOP , FORLOOP AND UNTIL LOOP IN A TABLE FORMAT :

|                   | While Loop                          | For Loop                                          | Until Loop            |
|-------------------|-------------------------------------|---------------------------------------------------|-----------------------|
| Condition Checks  | Executes as long as condition is true | Iterates over a list of items and executes for each item | Executes as long as condition is false |
| Use Case          | When the number of iterations is not known beforehand | When you want to iterate over a list of items | When you want to loop until a condition becomes true |



# Arithmetic Operations 

This is important when you want to perform mathematical calculations in your bash shell scripts

1. use it like $((expression)) or $(expression) for arithmetic operations.That is by using a double or single Parenthensis 

`syntax or format` 
result=$((5+3))
echo $result

or 

results=$(expr 5 + 3)
echo "5 + 3 = $results"

For Arithmetic Operations you can carryout the following calculations

 + addition 
 - subtraction 
 * Multiplication 
 / division 
 % Modulus /remainder of division 
 ** Exponentiation 
 ++  Increment 
 -- decrement 

e.g

### expr 

results=$(expr 5 + 3)
echo "5 + 3 = $results

or 

### Double Parenthensis $((  ))  
results=$((5+3))
echo "5 + 3 = $results 

### Addition (sum)  + 
a=5
b=2
sum=$((a + b))
echo "sum: $sum"

### subtraction (difference) - 

a=5
b=2
difference=$((a - b))
echo "difference: $difference"


a=5
b=2
eggs=$((a * b))
echo "eggs: $eggs"


###  Divison /

a=5
b=2
eggs=$((a / b))
echo "eggs: $eggs"

 ###  Modulus  (Remainder ) %

a=5
b=2
remainder =$((a % b))
echo "remainder: $remainder"

 ###  Increment  and Decrement ++

 increment 

a=5
((a++))
echo "increment a: $a"

decrement 
a=5
((a--))
echo "increment a: $a"


# ARRAYS 

Arrays are special variables which becomes handy when you want to handle multiple values in a single variable name OR Arrays can store multiple values in a single variable

`syntax (format)`

fruits=("apple" "mango" "banana")


use case : This is handy when you want your script to loop through a list of items 

# Functions 

 Functions allow you to bundle your code for repeated use .Makes your bash shell script or code well organised and maintanable .
 
 `syntax-1` 

function_name() {
    code or commands
}
function_name 

`e.g` : 

#!/bin/bash 

grace() {
    echo "Grace is the only one in class"
}
grace 


`syntax-2`

function "function_name" () {
    code 
}

e.g

function grace () {
 echo "Grace is the only one in class"
}
grace 


# Input & Output 

1. `Ouput syntax` : we have the following output syntax or commands 

+ `echo` : The echo command is used to display text or variables on the terminal e.g echo "welcome to team4tech solutions"

+ `printf`: This is similar to the echo but more formatted and supports string formatting (like in C programming).

2. `Input Syntax` : 

+ `read` : the read command accepts input from the user 
e.g

#!/bin/bash 

read -p "Enter your name: " name 
echo "welcome to team4tech solutions $name"

+ you can also use this to read from a file that is input  `<` this will take input from a file 

e.g 

while IFS= read -r line; do
  echo "$line"
done < file.txt


while [condition]; do 
  # commands 
done 


# Case Statements 

Case statements in Bash allow you to execute different code blocks based on the value of a variable. They're particularly useful when you need to check a variable against multiple possible values or patterns, making them more readable and efficient than a series of if-elif statements.

syntax 

case "$VARIABLE" in 
"pattern1")
  # code to execute if variables matches pattern one
;;
"pattern1")
   # code to execute if variables matches pattern one
;;
"pattern2")
   # code to execute if variables matches pattern one
;;

*)
   # code to execute if Variables doesnt match any pattern
;;

esac

+ case: Begins the case statement, followed by the variable you’re testing ($VARIABLE in this example).
+ in: Signals the start of the different patterns to match.
+ Patterns ("pattern1", "pattern2", etc.): Each pattern is a possible value of the variable. If the variable matches a pattern, the code block below it is executed.
+ Code Block: Code to run if the pattern matches. Each code block ends with ;; to prevent the execution from falling through to the next case.
+ * (Wildcard): This is the default case. It executes if no other patterns match.

+ esac: Ends the case statement (it’s "case" spelled backward).

`e.g`

#!/bin/bash 

#this a case statement script for practise 

read -p "Enter a fruit (apple, banana, cherry, pear): " FRUIT

case "$FRUIT" in 
  "apple")
     echo "Apples are red or green."
     ;;
  "banana")
     echo "Bananas are yellow."
     ;;
  "cherry")
     echo "Cherries are red"
     ;;
  "pear") 
     echo "pears are green"
     ;;
     
  *)
     echo "unkown fruit."
     ;;
    
esac


# Script Arguments or  parameters

These are special variables in bash shell scripting that hold specific information (static meaning it does not change)
They are system define parameter (variables ) (they come with the operating system)

There are two types of Parameters or Arguments 

1. Positional Parameters

echo "First argument:$1"
echo "All arguments: $@"


| Variable | Description                                                      |
|----------|------------------------------------------------------------------|
| `$0`     | The name of the script.                                          |
| `$1`, `$2`, ... `$N` | The first, second, ..., 3th argument passed to the script. |
| `$#`     | The number of arguments passed to the script.                    |
| `$@`     | All the arguments passed to the script, as separate words.       |
| `$*`     | All the arguments passed to the script, as a single word.        |
| `"$@"`   | All the arguments passed to the script, each quoted separately.  |
| `"$*"`   | All the arguments passed to the script, quoted as a single string. |





2. Special Variables or parameters 


## Special Purpose Variables

| Variable | Description                                     |
|----------|-------------------------------------------------|
| `$$`     | The process ID (PID) of the current shell.      |
| `$?`     | The exit status of the last executed command.   |
| `$!`     | The PID of the last background process.         |
| `$_`     | The last argument of the previous command.      |





`example 1` 

#!/bin/bash

# Check if exactly two arguments are provided
if [ $# -ne 2 ]; then
    echo "Usage: $0 you need to put two numbers as an argument before this script will run"
    exit 1
fi

# Read arguments into variables
num1=$1
num2=$2

# Perform addition
sum=$((num1 + num2))

# Output the result
echo "The sum of $num1 and $num2 is: $sum"



`example 2`

#!/bin/bash

# Check if at least two arguments are provided
if [ "$#" -lt 2 ]; then
    echo "please provide Usage: $0 <source_directory> <backup_directory> [backup_name]"
    exit 1
fi

# Assign positional parameters to variables
SOURCE_DIR=$1
BACKUP_DIR=$2
BACKUP_NAME=${3:-backup_$(date +%Y%m%d)}

# Create the backup directory if it doesn't exist
mkdir -p "$BACKUP_DIR"

# Perform the backup using tar
tar -czf "$BACKUP_DIR/$BACKUP_NAME.tar.gz" -C "$SOURCE_DIR" .

# Print a success message
echo "Backup of $SOURCE_DIR completed successfully."
echo "Backup file created: $BACKUP_NAME.tar.gz"




| Variable | Description                                                      |
|----------|------------------------------------------------------------------|
| `$0`     | The name of the script.                                          |
| `$1`, `$2`, ... `$N` | The first, second, ..., 3th argument passed to the script. |
| `$#`     | The number of arguments passed to the script.                    |
| `$@`     | All the arguments passed to the script, as separate words.       |
| `$*`     | All the arguments passed to the script, as a single word.        |
| `"$@"`   | All the arguments passed to the script, each quoted separately.  |
| `"$*"`   | All the arguments passed to the script, quoted as a single string. |



# Command Substituion 

Date=$(date)
echo "Today is $DATE"



**HOW TO TROUBLESHOOT OR DEBUG A BASH SCRIPT** 

`Debugging` is a process of identifying , analyzing and fixing issues , bugs , errors in code or a system.
Bugs can be caused by logical errors, syntax issues, or unexpected behaviors in the software or system, and debugging is essential for ensuring that the code functions as intended. 
+ The word debugging is taken from the word bug . so what is a bug 

What is a `Bug`?

A bug is an error, flaw, or unintended behavior in code that prevents the program from performing as expected. Bugs can manifest in many ways, including crashes, incorrect results, performance issues, or unexpected outputs.


`What is the Purpose of Debugging a Code or Script ?`

+ Helps ensure the software behaves as expected.
+ It Improves code quality and reliability.
+ Allows developers to identify and fix potential security vulnerabilities.
+ Increases performance by optimizing code after discovering inefficiencies.


`What are the steps or process to debug a code ?`

1.  Identify the bug : This is often done by running the script in bash or testing the software and observing unexpected behaviors, errors, or warnings.

2. Reproducing the Bug: Consistently reproducing the bug (if possible) helps to understand under what conditions it occurs, making it easier to investigate and fix.

3. Analyzing the Bug: Here, the developer analyzes the code and tracks down the root cause of the issue, often using debugging tools or techniques.

4. Fixing the Bug: Once the root cause is identified, the developer can modify the code to fix the issue.

5. Testing the Fix: After applying the fix, the code is re-tested to ensure that the bug is resolved and that no new bugs were introduced.

6. Documenting the Fix: It’s often helpful to document the cause of the bug and the steps taken to resolve it, both for future reference and for other developers working on the same project.



**What is trouble shooting**

Troubleshooting is the process of identifying, diagnosing, and resolving issues or problems within a system, device, software, or network. It is often used to address technical problems by systematically ruling out possible causes until the root cause of the problem is found and fixed.


**Difference between Troubleshooting and Debugging a code**

| Feature               | Troubleshooting                                          | Debugging                                             |
|-----------------------|----------------------------------------------------------|-------------------------------------------------------|
| **Definition**        | Process of identifying and resolving issues in a system or device, often addressing both hardware and software issues. | Process of finding and fixing code errors or bugs within software applications. |
| **Focus Area**        | System-wide issues, including hardware, software, and configurations. | Software code and logic issues.                        |
| **Primary Scope**     | Broader scope, applicable to various fields (IT, engineering, electronics, etc.). | Specific to software development.                      |
| **Typical Tools**     | Diagnostic tools, logs, physical inspections, network analyzers. | Debuggers, code editors, print statements, IDEs.       |
| **Common Techniques** | Divide and conquer, component swapping, system logs, consult documentation, ask the user. | Breakpoints, step-by-step execution, print statements, code inspection. |
| **Skill Set Required**| Knowledge of systems, hardware, software configurations, and common issues. | Knowledge of programming languages, logic, and code structures. |
| **Output Goal**       | To restore system functionality or identify faulty components or configurations. | To correct code so that the software runs without errors and performs as expected. |
| **Example Scenario**  | Resolving network connectivity issues, fixing slow computer performance, identifying faulty hardware. | Fixing a syntax error, resolving a null pointer exception, debugging an infinite loop in code. |



Common Debugging Technique 

+ `Print statements` : Adding `print` or `echo` statements at different points in the code to observe the values of variables and the flow of execution
+ `Using Debuggers` : Tools like gdb (GNU Debugger), IDE debuggers (e.g., Visual Studio, PyCharm), or browser developer tools (for web development) allow you to pause code execution, step through code line-by-line, inspect variable values, and set breakpoints.
+ `Error Logs` : Many programming environments and frameworks generate logs that capture error messages, stack traces, and system messages. Analyzing logs can provide insight into what went wrong.
+ `Breakpoints`: Setting breakpoints allows you to pause execution at specific points in the code, inspect the program state, and identify where things might be going wrong.
+ `Code Review`: Reviewing code with another developer  can sometimes reveal overlooked errors or logical mistakes.



1- **Using "set" Command Options**

set -x : Enables a mode of the shell where all executed commands are printed to the terminal . This useful for tracing the flow of the script .
set -e : This causes the script to exit immiedtaly if any command returns a non zero status 
set -u : Treats unset variables as an error when performing parameter expansion 
set -o  pipefail : Causes the pipeline to return the exit status of the last command in the pipe that failed 



`EXAMPLE` 

#!/bin/bash
# this script tells you how busy i am during the days of the week 
set -x 

day_of_week=$1  # Take the first command line argument

case $day_of_week in
    Monday)
        echo "Start of a new week!"
        ;;
    Tuesday|Wednesday|Thursday)
        echo "It's a busy week!"
        ;;
    Friday)
        echo "Almost the weekend!"
        ;;
    Saturday|Sunday)
        echo "Enjoy the weekend!"
        ;;
    *)
        echo "Unknown day: $day_of_week"
        ;;
esac

set +x


2 . **Using 'bash -x or bash -v'**

This helps you to run your script in debugging options directly from the commandline 

+ `bash -x <script name>` : Its going to print each command and its arguments as they are executed 
+ `bash -v <script name>` : Prints each line of the script as it is read 

example :  bash -x "script name"


3. **Using 'trap'**
The trap command can catch and handle signals and other script errors.

`example` 

#!/bin/bash
trap 'echo "An error occured in line $LINENO"; exit 1' ERR

# your script commands here
echo "Running Script
false

4. **Adding 'echo' statements**

Adding this echo statements that is going to output information on the commandline in strategic points in your bash shell script 
can help you understand the flow and state of variables which will make it easy to determined where the script is failing or having issues .
        
#!/bin/bash

echo "Starting script"
var="Hello World"
echo "variable value: $var"




# Common Questions about Bash shell scripts 

+ What is your experience with Bash Shell Scripting 
+ They can show you a bash shell script and ask you to tell them what the script is all about 
+ What if a developer writes a bash shell script or code and give what are the things you will be looking at as best practise 
+ Can you debug the script or how can debug a bash shell script .


USE CASE :  
+ Automate task ( Automating IAM Key rotation , Backing Important files into s3 bucket , use to monitor health of servers by checking CPU .memory and disk space usage )


## Exit Codes 

+ exit 0 : This indicates a succesful completion of your script 
+ exit 1 : This indicates an error occured during the execution of the scripts or command 
+ exit 2 : Can be used to indicate a different type of error , for example more severe error depending on the context or command .



+ Watch the videos 
+ Identification ( Can you identify all syntaxes ? )

